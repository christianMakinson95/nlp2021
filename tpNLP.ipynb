{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431fe738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dataclasses import make_dataclass\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import seaborn as sns\n",
    "import bitfinex as btf\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "compT, compR, compG = [], [],[]\n",
    "negT, negR, negG = [], [],[]\n",
    "posT, posR, posG = [], [],[]\n",
    "neuT, neuR, neuG = [], [],[]\n",
    "SIAT,SIAR, SIAG = 0, 0, 0\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import seaborn as sns\n",
    "import bitfinex as btf\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "\n",
    "from GoogleNews import GoogleNews\n",
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "\n",
    "import praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac40b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear una funcion para guardar puntajes de sentimiento con vaderSentiment\n",
    "def getSIA(text):\n",
    "  sia = SentimentIntensityAnalyzer()\n",
    "  sentiment = sia.polarity_scores(text)\n",
    "  return sentiment\n",
    "def setSIA(field,pos,neg,neu,comp):\n",
    "    for i in range(0, len(field)):\n",
    "      SIA = getSIA(field[i])\n",
    "      comp.append(SIA['compound'])\n",
    "      neg.append(SIA['neg'])\n",
    "      neu.append(SIA['neu'])\n",
    "      pos.append(SIA['pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702ac43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeleador(df):\n",
    "    labels=[]\n",
    "    for i in range(len(df)):\n",
    "        if df['Open'][i]:\n",
    "            if df['Open'][i]!=\"\" and df['Close'][i]!=\"\":\n",
    "                if int(float(df['Open'][i]))<int(float(df['Close'][i])):\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    df['Label']=labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae2ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaVacios(df):\n",
    "    for i in range(len(df)):\n",
    "        if \"nameUser\" in df['nameUser'][i]:\n",
    "            df = df.drop(index=i)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "def limpiaErroresR(df):\n",
    "    for i in range(len(df)):\n",
    "        if \"Title\" in df['Title'][i]:\n",
    "            df = df.drop(index=i)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "def limpiaErroresG(df):\n",
    "    for i in range(len(df)):\n",
    "        if \"Title\" in df['Title'][i]:\n",
    "            df = df.drop(index=i)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6f20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet = pd.read_csv('exportTweetData.csv')\n",
    "df_market = pd.read_csv('exportMarketData.csv')\n",
    "df_reddit = pd.read_csv('exportRedditData.csv')\n",
    "df_google = pd.read_csv('exportNewsData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cdfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetCombinadoTwitter = df_tweet.merge(df_market, how='inner', on='Date')\n",
    "dataSetCombinadoReddit = df_reddit.merge(df_market,how='inner', on='Date')\n",
    "dataSetCombinadoGoogle = df_google.merge(df_market, how='inner',on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648b5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetCombinadoTwitter = labeleador(dataSetCombinadoTwitter)\n",
    "\n",
    "dataSetCombinadoReddit = limpiaVacios(dataSetCombinadoReddit)\n",
    "dataSetCombinadoReddit = labeleador(dataSetCombinadoReddit)\n",
    "dataSetCombinadoReddit = limpiaErroresR(dataSetCombinadoReddit)\n",
    "\n",
    "dataSetCombinadoGoogle = limpiaErroresG(dataSetCombinadoGoogle)\n",
    "\n",
    "dataSetCombinadoGoogle = labeleador(dataSetCombinadoGoogle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b8edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "setSIA(dataSetCombinadoTwitter['Tweets'],posT,negT,neuT,compT)\n",
    "setSIA(dataSetCombinadoReddit['Title'],posR,negR,neuR,compR)\n",
    "setSIA(dataSetCombinadoGoogle['Desc'],posG,negG,neuG,compG)\n",
    "\n",
    "dataSetCombinadoTwitter['Compound'] = compT\n",
    "dataSetCombinadoTwitter['Negative'] = negT\n",
    "dataSetCombinadoTwitter['Neutral'] = neuT\n",
    "dataSetCombinadoTwitter['Positive'] = posT\n",
    "\n",
    "dataSetCombinadoReddit['Compound'] = compR\n",
    "dataSetCombinadoReddit['Negative'] = negR\n",
    "dataSetCombinadoReddit['Neutral'] = neuR\n",
    "dataSetCombinadoReddit['Positive'] = posR\n",
    "\n",
    "dataSetCombinadoGoogle['Compound'] = compG\n",
    "dataSetCombinadoGoogle['Negative'] = negG\n",
    "dataSetCombinadoGoogle['Neutral'] = neuG\n",
    "dataSetCombinadoGoogle['Positive'] = posG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47ffc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['Open','High','Low','Volume','Compound','Negative','Neutral','Positive','Label']\n",
    "trainDFLinealTwitter = dataSetCombinadoTwitter[keep_columns]\n",
    "trainDFLinealReddit = dataSetCombinadoReddit[keep_columns]\n",
    "trainDFLinealGoogle = dataSetCombinadoGoogle[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8bce4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para entrenamiento de programa con modelo lineal\n",
    "#Para modelo Lineal necesitamos np.array\n",
    "X_twitter = trainDFLinealTwitter\n",
    "X_twitter = np.array(X_twitter.drop('Label',1))\n",
    "\n",
    "#Create the target data set\n",
    "Y_twitter = np.array(dataSetCombinadoTwitter['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "88256ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para entrenamiento de programa con modelo lineal\n",
    "#Para modelo Lineal necesitamos np.array\n",
    "X_reddit = trainDFLinealReddit\n",
    "X_reddit = np.array(X_reddit.drop('Label',1))\n",
    "\n",
    "#Create the target data set\n",
    "Y_reddit = np.array(dataSetCombinadoReddit['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b49a3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para entrenamiento de programa con modelo lineal\n",
    "#Para modelo Lineal necesitamos np.array\n",
    "X_google = trainDFLinealGoogle\n",
    "X_google = np.array(X_google.drop('Label',1))\n",
    "\n",
    "#Create the target data set\n",
    "Y_google = np.array(dataSetCombinadoGoogle['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91bf1da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set de entrenamiento Twitter\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = train_test_split(X_twitter,Y_twitter, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec6bf334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        41\n",
      "           1       0.89      0.86      0.88        59\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.85      0.86      0.86       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n",
      "0.86\n"
     ]
    }
   ],
   "source": [
    "modelLDT = LinearDiscriminantAnalysis().fit(x_train_t,y_train_t)\n",
    "predLinearT = modelLDT.predict(x_test_t)\n",
    "\n",
    "with open(\"my_linearDiscAnalysis.sav\", 'wb') as f:\n",
    "    pickle.dump(modelLDT,f)\n",
    "print(classification_report(y_test_t, predLinearT))\n",
    "print(accuracy_score(y_test_t,predLinearT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fc7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set de entrenamiento Reddit\n",
    "#x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(X_reddit,Y_reddit, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2706d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LinearDiscriminantAnalysis().fit(x_train_r,y_train_r)\n",
    "#predLinearR = model.predict(x_test_r)\n",
    "#print(classification_report(y_test_r, predLinearR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8ee934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set de entrenamiento Google\n",
    "x_train_g, x_test_g, y_train_g, y_test_g = train_test_split(X_google,Y_google, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "454a41a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.90      0.75      0.78         6\n",
      "weighted avg       0.87      0.83      0.81         6\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis().fit(x_train_g,y_train_g)\n",
    "predLinearG = model.predict(x_test_g)\n",
    "print(classification_report(y_test_g, predLinearG))\n",
    "print(accuracy_score(y_test_g,predLinearG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc36ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagg of word para twitter\n",
    "bow_vectorizerT = CountVectorizer(max_df=0.9, min_df=2, max_features=1000, stop_words='english')\n",
    "bowT = bow_vectorizerT.fit_transform(dataSetCombinadoTwitter['Tweets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea4e8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagg of word para google\n",
    "bow_vectorizerG = CountVectorizer(max_df=0.9, min_df=2, max_features=1000, stop_words='english')\n",
    "bowG = bow_vectorizerG.fit_transform(dataSetCombinadoGoogle['Desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "401cae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagg of word para reddit\n",
    "#bow_vectorizerR = CountVectorizer(max_df=0.9, min_df=2, max_features=1000, stop_words='english')\n",
    "#bowR = bow_vectorizerR.fit_transform(dataSetCombinadoReddit['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10882e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para entrenamiento de programa con modelo regresivo Twitter\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = train_test_split(bowT,dataSetCombinadoTwitter['Label'], random_state = 42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d935b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para entrenamiento de programa con modelo regresivo Google\n",
    "x_train_g, x_test_g, y_train_g, y_test_g = train_test_split(bowG,dataSetCombinadoGoogle['Label'], random_state = 42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4288e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para entrenamiento de programa con modelo regresivo Reddit\n",
    "#x_train, x_test, y_train, y_test = train_test_split(bowR,dataSetCombinado['Label'], random_state = 42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1db8594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65        53\n",
      "           1       0.75      0.74      0.74        72\n",
      "\n",
      "    accuracy                           0.70       125\n",
      "   macro avg       0.70      0.70      0.70       125\n",
      "weighted avg       0.70      0.70      0.70       125\n",
      "\n",
      "0.704\n"
     ]
    }
   ],
   "source": [
    "modelLRT = LogisticRegression().fit(x_train_t,y_train_t)\n",
    "predRegT = modelLRT.predict(x_test_t)\n",
    "print(classification_report(y_test_t, predRegT))\n",
    "print(accuracy_score(y_test_t,predRegT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ebbfa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.43      0.50      0.46         7\n",
      "weighted avg       0.73      0.86      0.79         7\n",
      "\n",
      "0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "modelLRG = LogisticRegression().fit(x_train_g,y_train_g)\n",
    "predRegG = modelLRG.predict(x_test_g)\n",
    "print(predRegG)\n",
    "print(classification_report(y_test_g, predRegG))\n",
    "print(accuracy_score(y_test_g,predRegG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3efb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newPred = model.predict(df_tweet['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d92bd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = dataSetCombinadoTwitter['Tweets'].tolist()\n",
    "lblT = dataSetCombinadoTwitter['Label'].tolist()\n",
    "\n",
    "dataR = dataSetCombinadoReddit['Title'].tolist()\n",
    "lblR = dataSetCombinadoReddit['Label'].tolist()\n",
    "\n",
    "dataG = dataSetCombinadoGoogle['Desc'].tolist()\n",
    "lblG = dataSetCombinadoGoogle['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "322e583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "vectorizerT = TfidfVectorizer(max_features = 2500, max_df=0.8, stop_words = stopwords.words('english'))\n",
    "dataT = vectorizerT.fit_transform(dataT).toarray()\n",
    "\n",
    "#vectorizerR = TfidfVectorizer(max_features = 2500, max_df=0.8, stop_words = stopwords.words('english'))\n",
    "#dataR = vectorizerR.fit_transform(dataR).toarray()\n",
    "\n",
    "vectorizerG = TfidfVectorizer(max_features = 2500, max_df=0.8, stop_words = stopwords.words('english'))\n",
    "dataG = vectorizerG.fit_transform(dataG).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7e689cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t, x_test_t, y_train_t, y_test_t = train_test_split(dataT, lblT, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(dataR, lblR, test_size = 0.2, random_state = 0)\n",
    "\n",
    "x_train_g, x_test_g, y_train_g, y_test_g = train_test_split(dataG, lblG, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "913d7935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifierT = RandomForestClassifier(n_estimators = 200, random_state = 0)\n",
    "text_classifierT.fit(x_train_t, y_train_t)\n",
    "\n",
    "#text_classifierR = RandomForestClassifier(n_estimators = 200, random_state = 0)\n",
    "#text_classifierR.fit(x_train_r, y_train_r)\n",
    "\n",
    "text_classifierG = RandomForestClassifier(n_estimators = 200, random_state = 0)\n",
    "text_classifierG.fit(x_train_g, y_train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae6e4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsT = text_classifierT.predict(x_test_t)\n",
    "\n",
    "#predictionsR = text_classifierR.predict(x_test_r)\n",
    "\n",
    "predictionsG = text_classifierG.predict(x_test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d288bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24 17]\n",
      " [37 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.59      0.47        41\n",
      "           1       0.56      0.37      0.45        59\n",
      "\n",
      "    accuracy                           0.46       100\n",
      "   macro avg       0.48      0.48      0.46       100\n",
      "weighted avg       0.49      0.46      0.46       100\n",
      "\n",
      "0.46\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_t,predictionsT))\n",
    "print(classification_report(y_test_t,predictionsT))\n",
    "print(accuracy_score(y_test_t,predictionsT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e962205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_test_r,predictionsR))\n",
    "#print(classification_report(y_test_r,predictionsR))\n",
    "#print(accuracy_score(y_test_r,predictionsR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb0b1a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.33      0.50      0.40         6\n",
      "weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_g,predictionsG))\n",
    "print(classification_report(y_test_g,predictionsG))\n",
    "print(accuracy_score(y_test_g,predictionsG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15fb0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gauseano\n",
    "modelT = GaussianNB()\n",
    "modelG = GaussianNB()\n",
    "modelR = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0b02cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelT.fit(x_train_t, y_train_t)\n",
    "modelG.fit(x_train_g, y_train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f0dd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionT = modelT.predict(x_test_t)\n",
    "predictionG = modelG.predict(x_test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3db7b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24 17]\n",
      " [37 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.59      0.47        41\n",
      "           1       0.56      0.37      0.45        59\n",
      "\n",
      "    accuracy                           0.46       100\n",
      "   macro avg       0.48      0.48      0.46       100\n",
      "weighted avg       0.49      0.46      0.46       100\n",
      "\n",
      "0.46\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_t,predictionsT))\n",
    "print(classification_report(y_test_t,predictionsT))\n",
    "print(accuracy_score(y_test_t,predictionsT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87c0097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.33      0.50      0.40         6\n",
      "weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\christian\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_g,predictionsG))\n",
    "print(classification_report(y_test_g,predictionsG))\n",
    "print(accuracy_score(y_test_g,predictionsG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33c4b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mejor Score\n",
    "#Twitter -> Regression ~= 70\n",
    "#Google -> Regression ~= 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53fbe4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acceso a Twitter API\n",
    "consumerKey = \"TwlSxQ7X0qOJ9XPYi0RRGFmPy\"\n",
    "consumerSecret = \"4QCBGcgWOOhHWXe0SwDu5UMVGVSZvnZujkHhacliUQeBigM7ZS\"\n",
    "accessToken = \"1083093878893432836-HW9vv7t1xihZvZvq0YdomkNKPzFnWe\"\n",
    "accessTokenSecret = \"PW8gxDGBCaNcprbkIb0uEQstg5tUzL55KRWEOI8Vqz2U9\"\n",
    "\n",
    "authenticate = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "authenticate.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(authenticate, wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f35e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LimpiaTexto\n",
    "def cleanText(twt):\n",
    "    EMOJI_PATTERN = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"\\U000024C2-\\U0001F251\" \n",
    "    \"]+\"\n",
    "    )\n",
    "    twt = re.sub('#[A-Za-z0-9]+','',twt) #Removes any string with hash\n",
    "    twt = re.sub(r'[0-9]+', '', twt)\n",
    "    twt = re.sub('@[A-Za-z0-9]+','',twt) #Removes any string with at\n",
    "    twt = re.sub('\\\\n','',twt) #Remove \\n caracter\n",
    "    twt = EMOJI_PATTERN.sub(r'', twt)\n",
    "    twt = twt.replace('!','').replace('-','').replace('_','')\n",
    "    twt = re.sub('https?:\\/\\/\\S+','',twt) #Removes hastag\n",
    "    return twt\n",
    "def cleanTime(time):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "def cleanTimeStamp(time):\n",
    "    return datetime.fromtimestamp(time).strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fd167e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No keys, only access to public API functions\n"
     ]
    }
   ],
   "source": [
    "analyzedCrypto = 'BTC'\n",
    "#CREAR DATASET DE TWEETS\n",
    "cantidadDeTweetsBuscados = 500\n",
    "#loopeo para obtener y almacenar info de todas las monedas\n",
    "\n",
    "search_term = analyzedCrypto+' -filter:retweets'\n",
    "#mySince = datetime.now()-timedelta(minutes=30)\n",
    "#mySince = mySince.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#myUntil = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "mySince=\"2021-07-2\"\n",
    "myUntil=\"2021-07-2\"\n",
    "tweets = tweepy.Cursor(api.search, q=search_term, lang ='en', since=mySince, until=myUntil, tweet_mode='extended').items(cantidadDeTweetsBuscados)\n",
    "all_tweets = [tweet.full_text for tweet in tweets]\n",
    "\n",
    "tweets = tweepy.Cursor(api.search, q=search_term, lang ='en', since=mySince, until=myUntil,  tweet_mode='extended').items(cantidadDeTweetsBuscados)\n",
    "all_dates = [tweet.created_at for tweet in tweets]\n",
    "\n",
    "\n",
    "formatoDataSetTweets = {'Date': all_dates, 'Tweets': all_tweets}\n",
    "df_tweets = pd.DataFrame(data=formatoDataSetTweets)\n",
    "\n",
    "df_tweets['Tweets'] = df_tweets['Tweets'].apply(cleanText)\n",
    "df_tweets['Date'] = df_tweets['Date'].apply(cleanTime)\n",
    "\n",
    "#Genero dataSet con valores financieros\n",
    "api_v2 = btf.bitfinex_v2.api_v2()\n",
    "\n",
    "#CREAR DATASET DE VALORES DE MERCADO\n",
    "pair = analyzedCrypto\n",
    "TIMEFRAME = '30m'\n",
    "\n",
    "t_start = datetime(2021,6,2,0,0)\n",
    "t_start = time.mktime(t_start.timetuple())*1000\n",
    "\n",
    "t_stop = datetime(2021,7,2,0,0)\n",
    "t_stop = time.mktime(t_stop.timetuple())*1000\n",
    "\n",
    "result = api_v2.candles(symbol = 'BTCUSD', interval = TIMEFRAME, limit = 1000, start = t_start, end = t_stop)\n",
    "\n",
    "camposDataFrame = ['Date','Open', 'Close', 'High', 'Low', 'Volume']\n",
    "df_market = pd.DataFrame(result, columns=camposDataFrame)\n",
    "df_market['Date'] = pd.to_datetime(df_market['Date'], unit='ms')\n",
    "df_market['Date'] = df_market['Date'].apply(cleanTime)\n",
    "\n",
    "\n",
    "googlenews=GoogleNews(start='07/2/2021',end='07/2/2021')\n",
    "googlenews.search('Bitcoin')\n",
    "result=googlenews.result()\n",
    "camposDataFrame = ['title','media', 'datetime', 'desc']\n",
    "df_news=pd.DataFrame(result,columns=camposDataFrame)\n",
    "df_news['title']=df_news['title'].apply(cleanText)\n",
    "df_news['desc']=df_news['desc'].apply(cleanText)\n",
    "df_news.columns = ['Title','Media', 'Date', 'Desc']\n",
    "df_news['Date'] = df_news['Date'].apply(cleanTime)\n",
    "\n",
    "dataSetCombinadoGoogleActual = df_google.merge(df_market, how='inner',on='Date')\n",
    "dataSetCombinadoTwitterActual = df_tweet.merge(df_market, how='inner', on='Date')\n",
    "\n",
    "dataSetCombinadoTwitterActual = labeleador(dataSetCombinadoTwitter)\n",
    "dataSetCombinadoGoogleActual = limpiaErroresG(dataSetCombinadoGoogle)\n",
    "dataSetCombinadoGoogleActual = labeleador(dataSetCombinadoGoogle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5c8621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Label</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-27 23:59</td>\n",
       "      <td>Best  riskadjusted returns in the past  hours:...</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1</td>\n",
       "      <td>34660.0</td>\n",
       "      <td>34744.0</td>\n",
       "      <td>34750.0</td>\n",
       "      <td>34660.0</td>\n",
       "      <td>1.61210626</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                             Tweets  \\\n",
       "0  2021-06-27 23:59  Best  riskadjusted returns in the past  hours:...   \n",
       "\n",
       "   Subjectivity  Polarity  Label     Open    Close     High      Low  \\\n",
       "0         0.275     0.375      1  34660.0  34744.0  34750.0  34660.0   \n",
       "\n",
       "       Volume  Compound  Negative  Neutral  Positive  \n",
       "0  1.61210626    0.6369       0.0    0.682     0.318  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSetCombinadoTwitterActual.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b62863f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_linearDiscAnalysis.sav\",'rb') as f:\n",
    "    newModel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "161c82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posT,negT,neuT,compT = [],[],[],[]\n",
    "setSIA(dataSetCombinadoTwitterActual['Tweets'],posT,negT,neuT,compT)\n",
    "dataSetCombinadoTwitterActual['Compound'] = compT\n",
    "dataSetCombinadoTwitterActual['Negative'] = negT\n",
    "dataSetCombinadoTwitterActual['Neutral'] = neuT\n",
    "dataSetCombinadoTwitterActual['Positive'] = posT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d3caff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['Open','High','Low','Volume','Compound','Negative','Neutral','Positive']\n",
    "trainDFLinealTwitter2 = dataSetCombinadoTwitterActual[keep_columns]\n",
    "trainDFLinealTwitter2 = trainDFLinealTwitter2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3578ab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel.predict(trainDFLinealTwitter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96a05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
